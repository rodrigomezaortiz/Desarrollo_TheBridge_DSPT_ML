{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación\n",
    "\n",
    "Nos encontraremos que en muchos casos nuestro interés no es el de predecir un número continuo sino una variable categórica:\n",
    "\n",
    "* Es un cliente objetivo o no\n",
    "* Está enfermo o no\n",
    "* A qué grupo pertenece\n",
    "\n",
    "Esencialmente la clasificación requiere que etiquetemos nuestras muestras en una categoría y otra. Existen dos grande grupos de problemas en este ámbito:\n",
    "\n",
    "* Clasificación binaria, donde la categoría a predecir es binaria (SI o NO)\n",
    "* Clasificación multi-clase, donde la respuesta se presenta como una etiqueta perteneciente a una u otra categoría.\n",
    "\n",
    "Un problema multi-clase se puede tratar empleando multiples clasificadores binarios centrados en detectar una de las categorías, de manera que cuando veamos la construcción de modelos agrupados esto resultará más relevante. Por este motivo emplearemos muchos de los ejemplos centrándonos en los modelos de clasificación binarios.\n",
    "\n",
    "![classification](./img/classification.png)\n",
    "\n",
    "## Métricas\n",
    "\n",
    "Al igual que en el caso de la regresión, existen métricas específicas para determinar la bondad de un modelo (cómo de bueno es). En el caso de los problemas binarios sabemos que hay una clase positiva (1) y una negativa (0) que tomarán el significado de nuestro objetivo (enfermo/no-enfermo, virus/no-virus, etc.). Esto hace que muchas de las métricas tomen como base agrupaciones clave como la de los:\n",
    "\n",
    "* **Verdaderos Positivos (TP)**: decimos 1 y es 1\n",
    "* **Falsos Positivos (FP)**: decimos 1 pero es 0\n",
    "* **Verdaderos Negativos (TN)**: 0 y es 0\n",
    "* **Falsos Negativos (FN)**: decimos 0 y es 1\n",
    "\n",
    "![meme](./img/TNTFmeme.png)\n",
    "\n",
    "Si pusiéramos estas medidas en una matriz obtendríamos lo que se conoce como matriz de confusión que nos permite evaluar el rendimiento de un modelo en todos estos ejes.\n",
    "\n",
    "![confmat](./img/confmat.png)\n",
    "\n",
    "Fuente: https://en.wikipedia.org/wiki/Confusion_matrix\n",
    "\n",
    "### Accuracy\n",
    "\n",
    "El accuracy (exactitud) mide cómo de cerca han estado las decisiones de los valores reales disponibles. Por ello la forma de medir es en el caso bianrio:\n",
    "\n",
    "$$\n",
    "\n",
    "\\frac{TP+TN}{P+N}\n",
    "\n",
    "$$\n",
    "\n",
    "Y en el caso multi-clase\n",
    "\n",
    "$$\n",
    "\n",
    "\\frac{\\text{muestras correctamente clasificadas}}{\\text{todas las muestras}}\n",
    "\n",
    "$$\n",
    "\n",
    "Esta métricas puede llevar a equívoco en caso de **datos no balanceados**.\n",
    "\n",
    "### Precision\n",
    "\n",
    "La precisión es cómo de buenos somos acertando los casos positivos $\\frac{TP}{TP+FP}$\n",
    "\n",
    "### Recall (sensibilidad)\n",
    "\n",
    "La sensibilidad es cómo de bien respondemos a los casos positivos. ¿Hemos detectado todos? $\\frac{TP}{TP+FN}$\n",
    "\n",
    "### Specificity (especificidad)\n",
    "\n",
    "La especificidad es cuentas casos negativos hemos detectado correctamente. $\\frac{TN}{TN+FP}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas métricas cobran relevancia dependiendo de la preferencia de nuestro proceso y lo crítico que sea un mal diagnóstico en cada caso. Por ejemplo:\n",
    "\n",
    "* Si no queremos que se nos cuele ningún virus en nuestro ordenador, **priorizaremos la sensibilidad** pese a que esto pueda aumentar la tasa de falsos positivos.\n",
    "* Si no queremos dar por bueno un candidato a un puesto hasta que no sea el perfecto, **priorizaremos la precisión** aunque pierda algún candidato excepcional que no termine de encajar en todos los aspectos.\n",
    "\n",
    "# F-Score\n",
    "\n",
    "Existen métricas combinadas que intentan balancear el objetivo de nuestro entrenamiento. Este es el caso de la métrica $F_1$ que se representa como $2*\\frac{\\text{precicisón}*\\text{recall}}{\\text{precicisón}+\\text{recall}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación probabilística\n",
    "\n",
    "Muchas veces los modelos nos devolverán su categorización y un porcentaje asociado a la confianza de la etiqueta asignada, o incluso, basándonos en modelos de regresión veremos que lo que arrojan es un valor numérico entre 0 y 1 y dependiendo el umbral que seleccionemos seremos capaces de priorizar una mayor o menor detección de positivos en favor de más o menos falsos negativos.\n",
    "\n",
    "La curva ROC (Receiver Operating Characteristic) es una representación gráfica de cómo de bien funciona nuestro modelo ante distintos umbrales de detección para clasificación binaria. Se empleó en la segunda guerra mundial para analizar la capacidad de detección de distintos radares a la hora de detectar naves Japonesas (de ahí su nombre).\n",
    "\n",
    "![curva](./img/curvaroc.png)\n",
    "\n",
    "Si dibujamos el área bajo la curva podemos obtener una métrica de bondad, de manera que un 1 en el AUC (Area under the Curve) implica la perfección de nuestro modelo. Esta métrica funciona particularmente bien ante conjuntos de datos poco balanceados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos\n",
    "\n",
    "Veremos que existen distintos modelos que podemos emplear, provenientes de distintas ideas o aproximaciones al problema:\n",
    "\n",
    "* [Regresión logística](./Regresión%20logística/Introducción%20a%20la%20regresión%20logística.ipynb)\n",
    "* [Árboles de decisión](./Arboles%20de%20decisión.ipynb/Decision_trees.ipynb)\n",
    "* [Vecinos próximos](./Vecinos%20próximos/KNN_ejemplo.ipynb)\n",
    "* [Métodos basados en kernels](./Métodos%20basados%20en%20kernels/SVMs.ipynb)\n",
    "* [Agrupaciones de modelos](./Agrupaciones%20de%20modelos/Ensembles.ipynb) "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
